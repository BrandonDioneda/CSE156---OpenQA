{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a794baf-cf0f-4edd-b3ba-3301c2dcbca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForMultipleChoice, PreTrainedTokenizerFast\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.optim.swa_utils import AveragedModel, update_bn\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84b99d45-517f-4909-99b2-9d279a98d35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"microsoft/deberta-v3-base\"\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 1e-5\n",
    "NUM_EPOCHS = 10\n",
    "MAX_GRAD_NORM = 1.0\n",
    "WARM_UP_STEPS = 1000  # Warm-up steps\n",
    "SWA_START = 5\n",
    "PATIENCE = 3\n",
    "L2_REG = 1e-4  # L2 Regularization strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00ca55fd-ee9f-46c3-8769-6151eebcc3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"openbookqa\")\n",
    "train_data = dataset[\"train\"]\n",
    "dev_data = dataset[\"validation\"]\n",
    "test_data = dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "671e3055-2249-40cb-af1a-8092b0611799",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class OpenBookQAExample:\n",
    "    question_stem: str\n",
    "    choices: list\n",
    "    correct_idx: int\n",
    "\n",
    "    @staticmethod\n",
    "    def from_dict(data: dict):\n",
    "        label_to_idx = {'A': 0, 'B': 1, 'C': 2, 'D': 3}\n",
    "        question_stem = data['question_stem']\n",
    "        answerKey = data['answerKey']\n",
    "        correct_idx = label_to_idx[answerKey]\n",
    "        choices = [ch for ch in data['choices']['text']]\n",
    "        return OpenBookQAExample(question_stem=question_stem, choices=choices, correct_idx=correct_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f816c10-58fa-4f82-8f5b-d1b243d9cf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpenBookQADataset(torch.utils.data.Dataset):\n",
    "    tokenizer: PreTrainedTokenizerFast = None\n",
    "\n",
    "    def __init__(self, tokenizer, raw_data_list):\n",
    "        OpenBookQADataset.tokenizer = tokenizer\n",
    "        self.sample_list = [OpenBookQAExample.from_dict(d) for d in raw_data_list]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sample_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.sample_list[idx]\n",
    "\n",
    "    @staticmethod\n",
    "    def collate_fn(batch_samples):\n",
    "        stems = [ex.question_stem for ex in batch_samples]\n",
    "        list_of_choices = [ex.choices for ex in batch_samples]\n",
    "        labels = [ex.correct_idx for ex in batch_samples]\n",
    "\n",
    "        flattened_inputs = []\n",
    "        for stem, choices in zip(stems, list_of_choices):\n",
    "            for c in choices:\n",
    "                flattened_inputs.append(stem + \" \" + c)\n",
    "\n",
    "        tokenizer = OpenBookQADataset.tokenizer\n",
    "        tokenized = tokenizer(\n",
    "            flattened_inputs,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=128,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        batch_size = len(batch_samples)\n",
    "        num_choices = len(list_of_choices[0])\n",
    "        for k in tokenized:\n",
    "            tokenized[k] = tokenized[k].view(batch_size, num_choices, -1)\n",
    "\n",
    "        tokenized[\"labels\"] = torch.LongTensor(labels)\n",
    "        return tokenized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e13a0250-1439-408f-87c5-e1fc29b57464",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_openbookqa_datasets(tokenizer):\n",
    "    raw_data = load_dataset(\"openbookqa\", \"main\")\n",
    "    split_datasets = {}\n",
    "    for split_name in raw_data.keys():\n",
    "        split_data = list(raw_data[split_name])\n",
    "        split_datasets[split_name] = OpenBookQADataset(tokenizer, split_data)\n",
    "    return split_datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "603dcb8e-1e29-4209-a57c-5e574bbbace9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(preds, labels):\n",
    "    return (preds == labels).float().mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4aa27a23-b20f-4f00-b307-b5939c466454",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reinitialize_layers(model):\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, (nn.Linear, nn.LayerNorm)):\n",
    "            module.reset_parameters()\n",
    "            print(f\"Reinitialized {name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e33aaa9-0de7-4c82-9107-582daf91fd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, dataloader, optimizer, epoch, swa_model=None, swa_start=5, scheduler=None, clip_grad=1.0):\n",
    "    model.train()\n",
    "    all_preds, all_labels = [], []\n",
    "    progress_bar = tqdm(dataloader, desc=f\"Train Epoch {epoch}\", leave=True)\n",
    "\n",
    "    for batch in progress_bar:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        input_ids = batch[\"input_ids\"].cuda()\n",
    "        attn_mask = batch[\"attention_mask\"].cuda()\n",
    "        labels = batch[\"labels\"].cuda()\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attn_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "\n",
    "        loss = loss + L2_REG * sum(p.norm(2) for p in model.parameters())\n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip_grad)\n",
    "\n",
    "        optimizer.step()\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "\n",
    "        if swa_model and epoch >= swa_start:\n",
    "            swa_model.update_parameters(model)\n",
    "\n",
    "        preds = torch.argmax(logits, dim=1).detach().cpu()\n",
    "        labels_cpu = labels.detach().cpu()\n",
    "        all_preds.extend(preds.tolist())\n",
    "        all_labels.extend(labels_cpu.tolist())\n",
    "\n",
    "        progress_bar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n",
    "\n",
    "    accuracy = compute_accuracy(torch.tensor(all_preds), torch.tensor(all_labels))\n",
    "    print(f\"Train Epoch {epoch} - Loss: {loss.item():.4f} - Accuracy: {accuracy:.4f}\")\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26103234-394f-4b17-b1f9-114bf78d47ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, dataloader, split=\"Val\"):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    for batch in dataloader:\n",
    "        input_ids = batch[\"input_ids\"].cuda()\n",
    "        attn_mask = batch[\"attention_mask\"].cuda()\n",
    "        labels = batch[\"labels\"].cuda()\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attn_mask)\n",
    "        logits = outputs.logits\n",
    "        preds = torch.argmax(logits, dim=1).cpu()\n",
    "        all_preds.extend(preds.tolist())\n",
    "        all_labels.extend(labels.cpu().tolist())\n",
    "\n",
    "    accuracy = compute_accuracy(torch.tensor(all_preds), torch.tensor(all_labels))\n",
    "    print(f\"{split} Accuracy: {accuracy:.4f}\")\n",
    "    return accuracy.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b910bf2-b4c2-46d3-bdf7-e6be5697908c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Model Setup\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "    model = AutoModelForMultipleChoice.from_pretrained(MODEL_NAME).cuda()\n",
    "\n",
    "    # Optimizer and Scheduler\n",
    "    optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS)\n",
    "\n",
    "    # SWA Model Initialization\n",
    "    swa_model = AveragedModel(model)\n",
    "\n",
    "    # Load Datasets\n",
    "    datasets = initialize_openbookqa_datasets(tokenizer)\n",
    "    train_loader = DataLoader(datasets['train'], batch_size=BATCH_SIZE, shuffle=True, collate_fn=OpenBookQADataset.collate_fn)\n",
    "    val_loader = DataLoader(datasets[\"validation\"], batch_size=BATCH_SIZE, shuffle=False, collate_fn=OpenBookQADataset.collate_fn)\n",
    "    test_loader = DataLoader(datasets[\"test\"], batch_size=BATCH_SIZE, shuffle=False, collate_fn=OpenBookQADataset.collate_fn)\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    curr_patience = 0\n",
    "\n",
    "    # Training Loop\n",
    "    for epoch in range(1, NUM_EPOCHS+1):\n",
    "        train_acc = train_one_epoch(model, train_loader, optimizer, epoch, swa_model=swa_model, swa_start=SWA_START, scheduler=scheduler, clip_grad=MAX_GRAD_NORM)\n",
    "        val_acc = evaluate(model, val_loader, split=\"Val\")\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            model.save_pretrained(\"./checkpoints\")\n",
    "            curr_patience = 0\n",
    "        else:\n",
    "            curr_patience += 1\n",
    "            if curr_patience == PATIENCE:\n",
    "                break\n",
    "\n",
    "    # Evaluate Best Model\n",
    "    best_model = AutoModelForMultipleChoice.from_pretrained(\"./checkpoints\").cuda()\n",
    "    test_acc = evaluate(best_model, test_loader, split=\"Test\")\n",
    "    print(\"Final Test Acc:\", test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c274b8-9018-442b-a5d1-4d9ec96de8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
