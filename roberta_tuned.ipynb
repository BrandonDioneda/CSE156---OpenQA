{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cad99f2-a58d-4c55-82b5-954329b16f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForMultipleChoice, TrainingArguments, PreTrainedTokenizerFast\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.optim.swa_utils import AveragedModel, update_bn\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86ad96e2-8e26-4985-adac-e02660b1fbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"roberta-base\"\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 1e-5\n",
    "NUM_EPOCHS = 10\n",
    "MAX_GRAD_NORM = 1.0\n",
    "WARM_UP_STEPS = 1000  # Warm-up steps\n",
    "SWA_START = 5\n",
    "PATIENCE = 3\n",
    "L2_REG = 1e-4  # L2 Regularization strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec9f0c69-a3ae-44de-bda0-47a5fe051c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"openbookqa\")\n",
    "train_data = dataset[\"train\"]\n",
    "dev_data = dataset[\"validation\"]\n",
    "test_data = dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0043e75-2d78-4ff5-96fb-d518163fd577",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class OpenBookQAExample:\n",
    "    question_stem: str\n",
    "    choices: list\n",
    "    correct_idx: int\n",
    "\n",
    "    @staticmethod\n",
    "    def from_dict(data: dict):\n",
    "        label_to_idx = {'A': 0, 'B': 1, 'C': 2, 'D': 3}\n",
    "        question_stem = data['question_stem']\n",
    "        answerKey = data['answerKey']\n",
    "        correct_idx = label_to_idx[answerKey]\n",
    "        choices = [ch for ch in data['choices']['text']]\n",
    "        return OpenBookQAExample(question_stem=question_stem, choices=choices, correct_idx=correct_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33f61806-3103-45ff-82b6-c354bf0b5d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpenBookQADataset(torch.utils.data.Dataset):\n",
    "    tokenizer: PreTrainedTokenizerFast = None\n",
    "\n",
    "    def __init__(self, tokenizer, raw_data_list):\n",
    "        OpenBookQADataset.tokenizer = tokenizer\n",
    "        self.sample_list = [OpenBookQAExample.from_dict(d) for d in raw_data_list]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sample_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.sample_list[idx]\n",
    "\n",
    "    @staticmethod\n",
    "    def collate_fn(batch_samples):\n",
    "        stems = [ex.question_stem for ex in batch_samples]\n",
    "        list_of_choices = [ex.choices for ex in batch_samples]\n",
    "        labels = [ex.correct_idx for ex in batch_samples]\n",
    "\n",
    "        flattened_inputs = []\n",
    "        for stem, choices in zip(stems, list_of_choices):\n",
    "            for c in choices:\n",
    "                flattened_inputs.append(stem + \" \" + c)\n",
    "\n",
    "        tokenizer = OpenBookQADataset.tokenizer\n",
    "        tokenized = tokenizer(\n",
    "            flattened_inputs,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=128,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        batch_size = len(batch_samples)\n",
    "        num_choices = len(list_of_choices[0])\n",
    "        for k in tokenized:\n",
    "            tokenized[k] = tokenized[k].view(batch_size, num_choices, -1)\n",
    "\n",
    "        tokenized[\"labels\"] = torch.LongTensor(labels)\n",
    "        return tokenized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "473a3496-b398-484e-bebe-a4fdd50c50b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_openbookqa_datasets(tokenizer):\n",
    "    raw_data = load_dataset(\"openbookqa\", \"main\")\n",
    "    split_datasets = {}\n",
    "    for split_name in raw_data.keys():\n",
    "        split_data = list(raw_data[split_name])\n",
    "        split_datasets[split_name] = OpenBookQADataset(tokenizer, split_data)\n",
    "    return split_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "284dde10-72f6-4be1-b4f3-ae34ec3ec099",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(preds, labels):\n",
    "    return (preds == labels).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31ee5df8-7d7a-4cf5-9f91-9d32abcf5baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reinitialize_layers(model):\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, (nn.Linear, nn.LayerNorm)):\n",
    "            module.reset_parameters()\n",
    "            print(f\"Reinitialized {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "396de0ba-207c-4ffa-9ed4-fdecd1ea12a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, dataloader, optimizer, epoch, swa_model=None, swa_start=5, scheduler=None, clip_grad=1.0):\n",
    "    model.train()\n",
    "    all_preds, all_labels = [], []\n",
    "    progress_bar = tqdm(dataloader, desc=f\"Train Epoch {epoch}\", leave=True)\n",
    "\n",
    "    for batch in progress_bar:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        input_ids = batch[\"input_ids\"].cuda()\n",
    "        attn_mask = batch[\"attention_mask\"].cuda()\n",
    "        labels = batch[\"labels\"].cuda()\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attn_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "\n",
    "        loss = loss + L2_REG * sum(p.norm(2) for p in model.parameters())\n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip_grad)\n",
    "\n",
    "        optimizer.step()\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "\n",
    "        if swa_model and epoch >= swa_start:\n",
    "            swa_model.update_parameters(model)\n",
    "\n",
    "        preds = torch.argmax(logits, dim=1).detach().cpu()\n",
    "        labels_cpu = labels.detach().cpu()\n",
    "        all_preds.extend(preds.tolist())\n",
    "        all_labels.extend(labels_cpu.tolist())\n",
    "\n",
    "        progress_bar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n",
    "\n",
    "    accuracy = compute_accuracy(torch.tensor(all_preds), torch.tensor(all_labels))\n",
    "    print(f\"Train Epoch {epoch} - Loss: {loss.item():.4f} - Accuracy: {accuracy:.4f}\")\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40e19ee2-7c3f-4c72-8f02-b95b8b82bc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, dataloader, split=\"Val\"):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    for batch in dataloader:\n",
    "        input_ids = batch[\"input_ids\"].cuda()\n",
    "        attn_mask = batch[\"attention_mask\"].cuda()\n",
    "        labels = batch[\"labels\"].cuda()\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attn_mask)\n",
    "        logits = outputs.logits\n",
    "        preds = torch.argmax(logits, dim=1).cpu()\n",
    "        all_preds.extend(preds.tolist())\n",
    "        all_labels.extend(labels.cpu().tolist())\n",
    "\n",
    "    accuracy = compute_accuracy(torch.tensor(all_preds), torch.tensor(all_labels))\n",
    "    print(f\"{split} Accuracy: {accuracy:.4f}\")\n",
    "    return accuracy.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9378a952-98dc-4835-ad5f-2ec23bcae134",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Model Setup\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "    model = AutoModelForMultipleChoice.from_pretrained(MODEL_NAME).cuda()\n",
    "\n",
    "    # Optimizer and Scheduler\n",
    "    optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS)\n",
    "\n",
    "    # SWA Model Initialization\n",
    "    swa_model = AveragedModel(model)\n",
    "\n",
    "    # Load Datasets\n",
    "    datasets = initialize_openbookqa_datasets(tokenizer)\n",
    "    train_loader = DataLoader(datasets['train'], batch_size=BATCH_SIZE, shuffle=True, collate_fn=OpenBookQADataset.collate_fn)\n",
    "    val_loader = DataLoader(datasets[\"validation\"], batch_size=BATCH_SIZE, shuffle=False, collate_fn=OpenBookQADataset.collate_fn)\n",
    "    test_loader = DataLoader(datasets[\"test\"], batch_size=BATCH_SIZE, shuffle=False, collate_fn=OpenBookQADataset.collate_fn)\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    curr_patience = 0\n",
    "\n",
    "    # Training Loop\n",
    "    for epoch in range(1, NUM_EPOCHS+1):\n",
    "        train_acc = train_one_epoch(model, train_loader, optimizer, epoch, swa_model=swa_model, swa_start=SWA_START, scheduler=scheduler, clip_grad=MAX_GRAD_NORM)\n",
    "        val_acc = evaluate(model, val_loader, split=\"Val\")\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            model.save_pretrained(\"./checkpoints\")\n",
    "            curr_patience = 0\n",
    "        else:\n",
    "            curr_patience += 1\n",
    "            if curr_patience == PATIENCE:\n",
    "                break\n",
    "\n",
    "    # Evaluate Best Model\n",
    "    best_model = AutoModelForMultipleChoice.from_pretrained(\"./checkpoints\").cuda()\n",
    "    test_acc = evaluate(best_model, test_loader, split=\"Test\")\n",
    "    print(\"Final Test Acc:\", test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85faca0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
